### Попытка работы с Kafka, ClickHouse, Debezium, PostgreSQL, PySpark, PowerBI и Docker.

По ощущениям самый объемный, непонятно витееватый и структурированный, а также нифига не защищенный (можете брать токен, бот уже давно помер) тестовый проект на Python.

Ниже кратко описанно как ОНО вообще работает.
- Имеется бот технической поддержки, который собирает информацию о возникшей проблеме у пользователя и отправляет ее в PostgreSQL.
- PostgreSQL принимает данные от бота и пишет в базу.
  
  > Изначально хотел писать в базу статистику по проведенному времени в каждой вкладке (впрочем эмуляция передачи которой и производится в коде), чтобы понимать какая из них занимает у пользователя больше всего времени, но тогда так и не довел это до ума.
  > Поэтому просто эмулировал, т.к нужны были данные для аналитики.
- Так как PostgreSQL "представлял" собой stage слой, надо же переправить нужную информацию в базу для аналитики, да?) -> Передаем данные в ClickHouse.
- Но чтобы просто все не было, добавляем Kafka, а чтобы законектиться от PostgreSQL к Kafka - использовал Debezium, который я поднимал в Docker.
- Из Kafka данные топика передавались в ClickHouse
- Так как ClickHouse у нас "крутая штука для аналитики" -> подключаемся в PowerBI и строим графики.

Так или иначе, этот тестовый проект устаревший, имеет свои недоработки, да и было это давно
